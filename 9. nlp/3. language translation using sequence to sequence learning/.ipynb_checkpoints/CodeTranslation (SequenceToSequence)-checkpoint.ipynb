{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "def clean(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        cleaned.append(line)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "documentsV=[]\n",
    "documentsR=[]\n",
    "with open('fra.txt',encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        data=line.split(\"\\t\")\n",
    "        documentsV.append(data[0])\n",
    "        documentsR.append(data[1])\n",
    "documentsV=clean(documentsV)\n",
    "documentsR=clean(documentsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizerV = Tokenizer(filters=' ')\n",
    "tokenizerV.fit_on_texts(documentsV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizerR = Tokenizer(filters=' ')\n",
    "tokenizerR.fit_on_texts(documentsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_length(docs):\n",
    "    return max(len(d) for d in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rlength = max_length(documentsR)\n",
    "vlength = max_length(documentsV)\n",
    "r_vocab_size = len(tokenizerR.word_index) + 1\n",
    "v_vocab_size = len(tokenizerV.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(tokenizerV, vlength, documentsV)\n",
    "trainY = encode_sequences(tokenizerR, rlength, documentsR)\n",
    "trainY = encode_output(trainY, r_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 147, 256)          14336     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 192, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 192, 256)          525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 192, 57)           14649     \n",
      "=================================================================\n",
      "Total params: 1,079,609\n",
      "Trainable params: 1,079,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "# define model\n",
    "model = define_model(v_vocab_size, r_vocab_size, vlength, rlength, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 4.0451\n",
      "Epoch 2/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 3.9664\n",
      "Epoch 3/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 3.8421\n",
      "Epoch 4/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 3.5658\n",
      "Epoch 5/120\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 2.8158\n",
      "Epoch 6/120\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 1.1020\n",
      "Epoch 7/120\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 0.8902\n",
      "Epoch 8/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 1.1033\n",
      "Epoch 9/120\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 1.1677\n",
      "Epoch 10/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 1.1456\n",
      "Epoch 11/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 1.0842\n",
      "Epoch 12/120\n",
      "22/22 [==============================] - 1s 52ms/step - loss: 1.0097\n",
      "Epoch 13/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.9386\n",
      "Epoch 14/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.8831\n",
      "Epoch 15/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.8530\n",
      "Epoch 16/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.8523\n",
      "Epoch 17/120\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.8702\n",
      "Epoch 18/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.8853\n",
      "Epoch 19/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.8839\n",
      "Epoch 20/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.8676\n",
      "Epoch 21/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.8451\n",
      "Epoch 22/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.8243\n",
      "Epoch 23/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.8098\n",
      "Epoch 24/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.8025\n",
      "Epoch 25/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.8004\n",
      "Epoch 26/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.8010\n",
      "Epoch 27/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.8019\n",
      "Epoch 28/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.8016\n",
      "Epoch 29/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.7991\n",
      "Epoch 30/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.7943\n",
      "Epoch 31/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.7874\n",
      "Epoch 32/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.7785\n",
      "Epoch 33/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.7676\n",
      "Epoch 34/120\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 1.0669\n",
      "Epoch 35/120\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 1.0560\n",
      "Epoch 36/120\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 1.0347\n",
      "Epoch 37/120\n",
      "22/22 [==============================] - 1s 63ms/step - loss: 2.0374\n",
      "Epoch 38/120\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 0.9843\n",
      "Epoch 39/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.9645\n",
      "Epoch 40/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.9387\n",
      "Epoch 41/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.7041\n",
      "Epoch 42/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.6895\n",
      "Epoch 43/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.6577\n",
      "Epoch 44/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 2.3686\n",
      "Epoch 45/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 1.0204\n",
      "Epoch 46/120\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.6544\n",
      "Epoch 47/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.6662\n",
      "Epoch 48/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.6636\n",
      "Epoch 49/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.6502\n",
      "Epoch 50/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.6305\n",
      "Epoch 51/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.6067\n",
      "Epoch 52/120\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.5881\n",
      "Epoch 53/120\n",
      "22/22 [==============================] - 1s 63ms/step - loss: 0.6028\n",
      "Epoch 54/120\n",
      "22/22 [==============================] - 1s 63ms/step - loss: 0.5677\n",
      "Epoch 55/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.5759\n",
      "Epoch 56/120\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 0.5740\n",
      "Epoch 57/120\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.5559\n",
      "Epoch 58/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.5648\n",
      "Epoch 59/120\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 0.5955\n",
      "Epoch 60/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.6190\n",
      "Epoch 61/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.6086\n",
      "Epoch 62/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.5818\n",
      "Epoch 63/120\n",
      "22/22 [==============================] - 1s 67ms/step - loss: 0.6865\n",
      "Epoch 64/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.5708\n",
      "Epoch 65/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.5781\n",
      "Epoch 66/120\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 0.5741\n",
      "Epoch 67/120\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.5648\n",
      "Epoch 68/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5628\n",
      "Epoch 69/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.5658\n",
      "Epoch 70/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5628\n",
      "Epoch 71/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.5557\n",
      "Epoch 72/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5530\n",
      "Epoch 73/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.5545\n",
      "Epoch 74/120\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.5537\n",
      "Epoch 75/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.5494\n",
      "Epoch 76/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.5469\n",
      "Epoch 77/120\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.5479\n",
      "Epoch 78/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.5456\n",
      "Epoch 79/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.5414\n",
      "Epoch 80/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5404\n",
      "Epoch 81/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5396\n",
      "Epoch 82/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5364\n",
      "Epoch 83/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5343\n",
      "Epoch 84/120\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 0.5336\n",
      "Epoch 85/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5307\n",
      "Epoch 86/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5280\n",
      "Epoch 87/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.5270\n",
      "Epoch 88/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5246\n",
      "Epoch 89/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5219\n",
      "Epoch 90/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5208\n",
      "Epoch 91/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5183\n",
      "Epoch 92/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5159\n",
      "Epoch 93/120\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 0.5144\n",
      "Epoch 94/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5116\n",
      "Epoch 95/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5096\n",
      "Epoch 96/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.5074\n",
      "Epoch 97/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.5045\n",
      "Epoch 98/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.5024\n",
      "Epoch 99/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4994\n",
      "Epoch 100/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4977\n",
      "Epoch 101/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4950\n",
      "Epoch 102/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4939\n",
      "Epoch 103/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4931\n",
      "Epoch 104/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4925\n",
      "Epoch 105/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.4925\n",
      "Epoch 106/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4914\n",
      "Epoch 107/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4893\n",
      "Epoch 108/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4873\n",
      "Epoch 109/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4857\n",
      "Epoch 110/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4842\n",
      "Epoch 111/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4830\n",
      "Epoch 112/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.4823\n",
      "Epoch 113/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.4815\n",
      "Epoch 114/120\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.4803\n",
      "Epoch 115/120\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.4792\n",
      "Epoch 116/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4780\n",
      "Epoch 117/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.4767\n",
      "Epoch 118/120\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 0.4754\n",
      "Epoch 119/120\n",
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4743\n",
      "Epoch 120/120\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe3d417c6a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=120, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "def evaluate_model(model, tokenizer, sources, raw_src, raw_target):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, tokenizer, source)\n",
    "        #raw_target, raw_src = raw_dataset[i]\n",
    "        print('src=[%s], target=[%s], predicted=[%s]' % (raw_src[i], raw_target[i], translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {  echo  '<b>' ;  echo  $ _POST [ 'name' ] ;  echo  '</b>' ;  }  ?>], target=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {  echo  '<b>' ;  echo  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;  echo  '</b>' ;  }  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  echo  $ _POST [ 'name' ] ;  ?>], target=[ <? php  echo  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ ;]\n",
      "src=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  ' Welcome, '  .  $ name  .  '</div>' ;  ?>], target=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  ' Welcome, '  .   HTMLSpecialChars ( $ name )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  \"Welcome\" ;  echo  \"$name\"  ?>], target=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  \"Welcome\" ;  $ name  =  HTMLSpecialChars ( $ name ) ;  echo  \"$name\"  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      echo  $ _POST [ 'name' ] ;  }  ?>], target=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      $ name  =  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;      echo  $ name ;  }  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  ?>  < html > < body > Hello   <? php  echo  $ name ;  ?> ! < / body > < / html >], target=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  $ name  =  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;  ?>  < html > < body > Hello   <? php  echo  $ name ;  ?> ! < / body > < / html >], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  echo  $ _REQUEST  [ 'name' ] ;  ?> ], target=[ <? php  echo  HTMLSpecialChars ( $ _REQUEST  [ 'name' ] ) ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  $ name ;  ?> ], target=[ <? php  $ name  =  HTMLSpecialChars ( $ _REQUEST  [ 'name' ] ) ;  echo  $ name ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  \"Hi\" ;  echo  \"$name\"  ?>], target=[ <? php  $ name  =  HTMLSpecialChars ( $ _REQUEST  [ 'name' ] ) ;  echo  \"Hi\" ;  echo  \"$name\"  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  ' Hi, '  .  $ name  .  '</div>' ;  ?>], target=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  ' Hi, '  .  HTMLSpecialChars ( $ name )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  $ b ;  ?>], target=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _GET [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  $ b ;  ?>], target=[ <? php  $ a  =  $ _GET [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _REQUEST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  $ b ;  ?>], target=[ <? php  $ a  =  $ _REQUEST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  $ b ;  ?>], target=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      $ a  =  $ _POST [ 'name' ] ;      $ b  =  $ a ;      echo  \"Hello, \"  .  $ b ;  }  ?>], target=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      $ a  =  $ _POST [ 'name' ] ;      $ b  =  $ a ;      echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  }  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div class=\"header\"> Welcome, '  .  $ username  .  '</div>' ;  ?>], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div class=\"header\"> Welcome, '  .  HTMLSpecialChars ( $ username )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  \"Welcome $username<br>\" ;  ?> ], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  $ username  =  HTMLSpecialChars ( $ username ) ;  echo  \"Welcome $username<br>\" ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  \"Welcome\" ;  echo  \"$username\"  ?>], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  \"Welcome\" ;  $ username  =  HTMLSpecialChars ( $ username ) ;  echo  \"$username\"  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  echo  '<div class=\"header\"> Welcome, '  .  $ _GET [ 'username' ]  .  '</div>' ;  ?>], target=[ <? php  echo  '<div class=\"header\"> Welcome, '  .  HTMLSpecialChars ( $ _GET [ 'username' ] )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div> Welcome, '  .  $ username  .  '</div>' ;  ?>], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div> Welcome, '  .  HTMLSpecialChars ( $ username )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  if ( $ _POST ) {   $ color  =  $ _POST [ \"color\" ] ;   echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  }  ?> ], target=[ <? php  if ( $ _POST ) {   $ color  =  $ _POST [ \"color\" ] ;   $ color  =  HTMLSpecialChars ( $ color ) ;   echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  }  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  $ color  =  $ _POST [ \"color\" ] ;  echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  ?> ], target=[ <? php  $ color  =  HTMLSpecialChars ( $ _POST [ \"color\" ] ) ;  echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, tokenizerR, trainX, documentsV, documentsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
