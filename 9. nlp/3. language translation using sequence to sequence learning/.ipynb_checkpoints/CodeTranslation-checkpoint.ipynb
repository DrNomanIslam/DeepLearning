{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "def clean(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        cleaned.append(line)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "documentsV=[]\n",
    "documentsR=[]\n",
    "with open('fra.txt',encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        data=line.split(\"\\t\")\n",
    "        documentsV.append(data[0])\n",
    "        documentsR.append(data[1])\n",
    "documentsV=clean(documentsV)\n",
    "documentsR=clean(documentsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizerV = Tokenizer(filters=' ')\n",
    "tokenizerV.fit_on_texts(documentsV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizerR = Tokenizer(filters=' ')\n",
    "tokenizerR.fit_on_texts(documentsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_length(docs):\n",
    "    return max(len(d) for d in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rlength = max_length(documentsR)\n",
    "vlength = max_length(documentsV)\n",
    "r_vocab_size = len(tokenizerR.word_index) + 1\n",
    "v_vocab_size = len(tokenizerV.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(tokenizerV, vlength, documentsV)\n",
    "trainY = encode_sequences(tokenizerR, rlength, documentsR)\n",
    "trainY = encode_output(trainY, r_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3, 256)            82176     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 7, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 684)            175788    \n",
      "=================================================================\n",
      "Total params: 1,308,588\n",
      "Trainable params: 1,308,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "# define model\n",
    "model = define_model(v_vocab_size, r_vocab_size, vlength, rlength, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5725\n",
      "Epoch 2/10\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5285\n",
      "Epoch 3/10\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4822\n",
      "Epoch 4/10\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.4469\n",
      "Epoch 5/10\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4164\n",
      "Epoch 6/10\n",
      " 75/840 [=>............................] - ETA: 3s - loss: 1.2300"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=10, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "def evaluate_model(model, tokenizer, sources, raw_src, raw_target):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, tokenizer, source)\n",
    "        #raw_target, raw_src = raw_dataset[i]\n",
    "        print('src=[%s], target=[%s], predicted=[%s]' % (raw_src[i], raw_target[i], translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {  echo  '<b>' ;  echo  $ _POST [ 'name' ] ;  echo  '</b>' ;  }  ?>], target=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {  echo  '<b>' ;  echo  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;  echo  '</b>' ;  }  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  echo  $ _POST [ 'name' ] ;  ?>], target=[ <? php  echo  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ ;]\n",
      "src=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  ' Welcome, '  .  $ name  .  '</div>' ;  ?>], target=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  ' Welcome, '  .   HTMLSpecialChars ( $ name )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  \"Welcome\" ;  echo  \"$name\"  ?>], target=[ <? php  $ name  =  $ _POST [ 'name' ] ;  echo  \"Welcome\" ;  $ name  =  HTMLSpecialChars ( $ name ) ;  echo  \"$name\"  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      echo  $ _POST [ 'name' ] ;  }  ?>], target=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      $ name  =  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;      echo  $ name ;  }  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  ?>  < html > < body > Hello   <? php  echo  $ name ;  ?> ! < / body > < / html >], target=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  $ name  =  HTMLSpecialChars ( $ _POST [ 'name' ] ) ;  ?>  < html > < body > Hello   <? php  echo  $ name ;  ?> ! < / body > < / html >], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  echo  $ _REQUEST  [ 'name' ] ;  ?> ], target=[ <? php  echo  HTMLSpecialChars ( $ _REQUEST  [ 'name' ] ) ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  $ name ;  ?> ], target=[ <? php  $ name  =  HTMLSpecialChars ( $ _REQUEST  [ 'name' ] ) ;  echo  $ name ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  \"Hi\" ;  echo  \"$name\"  ?>], target=[ <? php  $ name  =  HTMLSpecialChars ( $ _REQUEST  [ 'name' ] ) ;  echo  \"Hi\" ;  echo  \"$name\"  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ;]\n",
      "src=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  ' Hi, '  .  $ name  .  '</div>' ;  ?>], target=[ <? php  $ name  =  $ _REQUEST  [ 'name' ] ;  echo  ' Hi, '  .  HTMLSpecialChars ( $ name )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  $ b ;  ?>], target=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _GET [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  $ b ;  ?>], target=[ <? php  $ a  =  $ _GET [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _REQUEST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  $ b ;  ?>], target=[ <? php  $ a  =  $ _REQUEST [ 'name' ] ;  $ b  =  $ a ;  echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  $ b ;  ?>], target=[ <? php  $ a  =  $ _POST [ 'name' ] ;  $ b  =  $ a ;  echo  HTMLSpecialChars ( $ b ) ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      $ a  =  $ _POST [ 'name' ] ;      $ b  =  $ a ;      echo  \"Hello, \"  .  $ b ;  }  ?>], target=[ <? php  if ( ! empty ( $ _POST [ 'name' ] ) ) {      $ a  =  $ _POST [ 'name' ] ;      $ b  =  $ a ;      echo  \"Hello, \"  .  HTMLSpecialChars ( $ b ) ;  }  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div class=\"header\"> Welcome, '  .  $ username  .  '</div>' ;  ?>], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div class=\"header\"> Welcome, '  .  HTMLSpecialChars ( $ username )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  \"Welcome $username<br>\" ;  ?> ], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  $ username  =  HTMLSpecialChars ( $ username ) ;  echo  \"Welcome $username<br>\" ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  \"Welcome\" ;  echo  \"$username\"  ?>], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  \"Welcome\" ;  $ username  =  HTMLSpecialChars ( $ username ) ;  echo  \"$username\"  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  echo  '<div class=\"header\"> Welcome, '  .  $ _GET [ 'username' ]  .  '</div>' ;  ?>], target=[ <? php  echo  '<div class=\"header\"> Welcome, '  .  HTMLSpecialChars ( $ _GET [ 'username' ] )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ;]\n",
      "src=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div> Welcome, '  .  $ username  .  '</div>' ;  ?>], target=[ <? php  $ username  =  $ _GET [ 'username' ] ;  echo  '<div> Welcome, '  .  HTMLSpecialChars ( $ username )  .  '</div>' ;  ?>], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ;]\n",
      "src=[ <? php  if ( $ _POST ) {   $ color  =  $ _POST [ \"color\" ] ;   echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  }  ?> ], target=[ <? php  if ( $ _POST ) {   $ color  =  $ _POST [ \"color\" ] ;   $ color  =  HTMLSpecialChars ( $ color ) ;   echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  }  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ; ; ; ; ;]\n",
      "src=[ <? php  $ color  =  $ _POST [ \"color\" ] ;  echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  ?> ], target=[ <? php  $ color  =  HTMLSpecialChars ( $ _POST [ \"color\" ] ) ;  echo  \"<div style='background:$color; height:300px; width:300px;'></div>\" ;  ?> ], predicted=[$ $ $ $ $ $ $ $ $ $ $ $ $ $ $ ; ; ; ;]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, tokenizerR, trainX, documentsV, documentsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
