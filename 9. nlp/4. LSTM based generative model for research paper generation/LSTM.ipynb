{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "U0wMCx_Truhs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "268e34fa-b26e-438e-aa9c-ee59228678d4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379741653,
          "user_tz": -300,
          "elapsed": 5317,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import random\n",
        "import sys\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yPLlr8OCruh0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "405900a5-ee9d-4c60-e9d9-85bc31bf07b0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379744213,
          "user_tz": -300,
          "elapsed": 1043,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "    distribution = np.log(original_distribution) / temperature\n",
        "    distribution = np.exp(distribution)\n",
        "    return distribution / np.sum(distribution)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4e0qGz8fruh2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "c3159b54-49fb-444c-fe89-c0429f8e63b7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379747200,
          "user_tz": -300,
          "elapsed": 1214,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def loadFile():\n",
        "    text = open('paper.txt').read().lower()\n",
        "    return text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oz1JxFpAruh5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8b4fcbe4-695a-4ee0-a721-b87591d1bfa3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379749203,
          "user_tz": -300,
          "elapsed": 1293,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "text = loadFile()\n",
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcLC-RKUruh9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "70309a6e-9597-4b11-a300-97357eec49e2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379754725,
          "user_tz": -300,
          "elapsed": 996,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters:', len(chars))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of sequences:', 27512)\n",
            "('Unique characters:', 68)\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M09EUwayruiB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "a335146a-c2d2-4634-de39-20ba7940f882",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379762836,
          "user_tz": -300,
          "elapsed": 1658,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "        y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bGAtKJwhruiE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "57e659c1-b004-4dda-8f1c-f421e0b8df6a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379764375,
          "user_tz": -300,
          "elapsed": 840,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3c2J8z7ruiG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "6b6c4ca6-7a7e-48bc-ad62-4858e1a0a75d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530379772939,
          "user_tz": -300,
          "elapsed": 1265,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Lou60cXruiK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1028
        },
        "outputId": "c2def2b0-15c6-4c55-ad3d-2dbc343d6a2c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530380923309,
          "user_tz": -300,
          "elapsed": 1072733,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=30, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.8214\n",
            "Epoch 2/30\n",
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.5720\n",
            "Epoch 3/30\n",
            "23424/27512 [========================>.....] - ETA: 5s - loss: 1.3965"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.3927\n",
            "Epoch 4/30\n",
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.2724\n",
            "Epoch 5/30\n",
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.1753\n",
            "Epoch 6/30\n",
            " 4480/27512 [===>..........................] - ETA: 29s - loss: 1.0338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.0940\n",
            "Epoch 7/30\n",
            "27512/27512 [==============================] - 35s 1ms/step - loss: 1.0213\n",
            "Epoch 8/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.9714\n",
            "Epoch 9/30\n",
            "  640/27512 [..............................] - ETA: 35s - loss: 0.8514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.9217\n",
            "Epoch 10/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.8888\n",
            "Epoch 11/30\n",
            "26880/27512 [============================>.] - ETA: 0s - loss: 0.8537"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.8541\n",
            "Epoch 12/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.8264\n",
            "Epoch 13/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.8025\n",
            "Epoch 14/30\n",
            " 4992/27512 [====>.........................] - ETA: 28s - loss: 0.6999"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.7829\n",
            "Epoch 15/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.7661\n",
            "Epoch 16/30\n",
            "21504/27512 [======================>.......] - ETA: 7s - loss: 0.7199"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 35s 1ms/step - loss: 0.7370\n",
            "Epoch 18/30\n",
            "27512/27512 [==============================] - 35s 1ms/step - loss: 0.7172\n",
            "Epoch 19/30\n",
            "27512/27512 [==============================] - 37s 1ms/step - loss: 0.7055\n",
            "Epoch 20/30\n",
            " 3840/27512 [===>..........................] - ETA: 31s - loss: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.6969\n",
            "Epoch 21/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.6914\n",
            "Epoch 22/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.6762\n",
            "Epoch 23/30\n",
            "  128/27512 [..............................] - ETA: 35s - loss: 0.6960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.6670\n",
            "Epoch 24/30\n",
            "27512/27512 [==============================] - 37s 1ms/step - loss: 0.6539\n",
            "Epoch 25/30\n",
            "26752/27512 [============================>.] - ETA: 1s - loss: 0.6458"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 37s 1ms/step - loss: 0.6476\n",
            "Epoch 26/30\n",
            "27512/27512 [==============================] - 37s 1ms/step - loss: 0.6410\n",
            "Epoch 27/30\n",
            "27512/27512 [==============================] - 37s 1ms/step - loss: 0.6279\n",
            "Epoch 28/30\n",
            " 4864/27512 [====>.........................] - ETA: 29s - loss: 0.5374"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.6221\n",
            "Epoch 29/30\n",
            "27512/27512 [==============================] - 36s 1ms/step - loss: 0.6213\n",
            "Epoch 30/30\n",
            "27512/27512 [==============================] - 38s 1ms/step - loss: 0.6029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1054315250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "o8gB7O0zruiO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "17c476e5-7334-40c9-de3a-18ce9aafb41e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530381540451,
          "user_tz": -300,
          "elapsed": 44068,
          "user": {
            "displayName": "Noman Islam",
            "photoUrl": "//lh6.googleusercontent.com/-AxOxrJvGTqY/AAAAAAAAAAI/AAAAAAAAADM/SWSNC7oBlZ0/s50-c-k-no/photo.jpg",
            "userId": "113190879662721490735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "generated_text = text[start_index: start_index + maxlen]\n",
        "print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "sys.stdout.write(generated_text)\n",
        "for i in range(1000):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "        sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, 0.5)\n",
        "    next_char = chars[next_index]\n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    if(i%100==0):\n",
        "        next_char+='\\n'\n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Generating with seed: \"ally, the service discovery requests that are issued in one \"\n",
            "ally, the service discovery requests that are issued in one d\n",
            "efininted events. an applies the services in mobile ng the service is available the a network l"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "y-dir\n",
            "eltion of the network. if node recentive bether is component is and records the postinations (manet \n",
            "is aven alsowe the service discovery sthed in association rules mining algorithm. the services in ot\n",
            " deperame the service discovery requests with the service discovery in mobile communing iscunter\n",
            " of the paper wish discovery in manet. services available the approach is based on the service disco\n",
            "very algorithm is ad hoc networks shorkes hovery when shoriet is is nourses and the service discover\n",
            "y in mobile the service discovery requests the resiscins nodes in manet, as as the service. the prop\n",
            "osed approach is broadcasts the service is available on the node receiving the service. the proposed\n",
            " approach we have by a nogess probist, the service discovery in mobile latenc. in this paper we have\n",
            " service discovery is mobile discovery is manet. anot a compunentires local conse the poperations. "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EKe8EjQzz7yf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}